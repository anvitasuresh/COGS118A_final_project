{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb4f27b-ade7-4871-b4a8-cbf68b1255f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, learning_curve, LeaveOneOut, StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff78f00-d5ed-4850-9922-e1e4fd6e357b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET 1: HEART DISEASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2481dd-f369-43fc-96b0-8704366e0bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "df = pd.read_csv('processed.cleveland.data', header=None, na_values=\"?\")\n",
    "\n",
    "# column names\n",
    "columns = [\n",
    "    \"age\", \"sex\", \"cp\", \"trestbps\", \"chol\", \"fbs\", \"restecg\", \"thalach\", \"exang\",\n",
    "    \"oldpeak\", \"slope\", \"ca\", \"thal\", \"target\"\n",
    "]\n",
    "df.columns = columns\n",
    "\n",
    "# drop missing values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# converting target to binary (1 for presence of heart disease, 0 for absence)\n",
    "df[\"target\"] = df[\"target\"].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "X = df.drop(\"target\", axis=1)\n",
    "y = df[\"target\"]\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650c0b1a-d8de-441e-87e2-3dfbb7ee6bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifiers and hyperparameter grids\n",
    "param_grids = {\n",
    "    \"SVM\": {\n",
    "        \"C\": [0.1, 1, 10, 100],\n",
    "        \"gamma\": [0.01, 0.1, 1, 'scale'],\n",
    "        \"kernel\": [\"rbf\", \"linear\"]\n",
    "    },\n",
    "    \"Random Forest\": {\n",
    "        \"n_estimators\": [50, 100, 200],\n",
    "        \"max_depth\": [None, 5, 10, 20],\n",
    "        \"min_samples_split\": [2, 5, 10]\n",
    "    },\n",
    "    \"KNN\": {\n",
    "        \"n_neighbors\": [3, 5, 7, 9, 11],\n",
    "        \"weights\": [\"uniform\", \"distance\"],\n",
    "        \"metric\": [\"euclidean\", \"manhattan\"]\n",
    "    },\n",
    "    \"Logistic Regression\": {\n",
    "        \"C\": [0.01, 0.1, 1, 10, 100],\n",
    "        \"penalty\": [\"l2\"],\n",
    "        \"solver\": [\"lbfgs\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "classifiers = {\n",
    "    \"SVM\": SVC(kernel='rbf', C=1, gamma='scale'),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42)\n",
    "}\n",
    "\n",
    "\n",
    "best_models = {}\n",
    "\n",
    "# performing grid search for hyperparameter tuning \n",
    "\n",
    "for clf_name, clf in classifiers.items():\n",
    "    print(f\"\\n--- Tuning Hyper-Parameters for {clf_name} ---\")\n",
    "    grid_search = GridSearchCV(clf, param_grids[clf_name], cv=5, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "    grid_search.fit(X, y)\n",
    "    best_models[clf_name] = grid_search.best_estimator_\n",
    "    print(f\"Best Parameters for {clf_name}: {grid_search.best_params_}\")\n",
    "    print(f\"Best Cross-Validation Accuracy: {grid_search.best_score_:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfb06c1-9fce-4f12-8f9b-5044cb0d5f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluating classfiers on different training and test sizes \n",
    "\n",
    "def evaluate_with_partitions(X, y, models, n_repeats=3):\n",
    "    splits = {\n",
    "        \"20/80\": 0.2,\n",
    "        \"50/50\": 0.5,\n",
    "        \"80/20\": 0.8\n",
    "    }\n",
    "    \n",
    "    for split_name, test_size in splits.items():\n",
    "        print(f\"\\n--- Train-Test Split: {split_name} ---\")\n",
    "        \n",
    "        for _ in range(n_repeats):\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=None)\n",
    "            \n",
    "            for clf_name, clf in models.items():\n",
    "                # train the classifier\n",
    "                clf.fit(X_train, y_train)\n",
    "                \n",
    "                # predict and calculate accuracy\n",
    "                y_train_pred = clf.predict(X_train)\n",
    "                y_test_pred = clf.predict(X_test)\n",
    "                \n",
    "                train_acc = accuracy_score(y_train, y_train_pred)\n",
    "                test_acc = accuracy_score(y_test, y_test_pred)\n",
    "                \n",
    "                print(f\"{clf_name}: Train Accuracy = {train_acc:.4f}, Test Accuracy = {test_acc:.4f}\")\n",
    "\n",
    "# evaluate classifiers with tuned hyper-parameters\n",
    "results = evaluate_with_partitions(X, y, best_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b0fa93-6cfa-4d5f-bb18-5d3d96fb6cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(model, X, y, title):\n",
    "    train_sizes, train_scores, val_scores = learning_curve(\n",
    "        model, X, y, cv=5, scoring='accuracy', train_sizes=np.linspace(0.1, 1.0, 10), n_jobs=-1\n",
    "    )\n",
    "\n",
    "    train_mean = np.mean(train_scores, axis=1)\n",
    "    train_std = np.std(train_scores, axis=1)\n",
    "    val_mean = np.mean(val_scores, axis=1)\n",
    "    val_std = np.std(val_scores, axis=1)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_sizes, train_mean, 'o-', color=\"r\", label=\"Training Accuracy\")\n",
    "    plt.plot(train_sizes, val_mean, 'o-', color=\"g\", label=\"Validation Accuracy\")\n",
    "    plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.1, color=\"r\")\n",
    "    plt.fill_between(train_sizes, val_mean - val_std, val_mean + val_std, alpha=0.1, color=\"g\")\n",
    "    \n",
    "    plt.title(f\"Learning Curve for {title}\")\n",
    "    plt.xlabel(\"Training Size\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "# plot learning curves for each classifier with training and validation accuracy\n",
    "for clf_name, clf in best_models.items():\n",
    "    plot_learning_curve(clf, X, y, clf_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73766f00-7780-4742-a44f-6697b2078baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_classifiers(X, y, classifiers, cv=5):\n",
    "    print(\"\\n--- Cross-Validation Results for Heart Disease Dataset ---\")\n",
    "    \n",
    "    for clf_name, clf in classifiers.items():\n",
    "        scores = cross_val_score(clf, X, y, cv=cv, scoring='accuracy')\n",
    "        print(f\"{clf_name}: Mean Accuracy = {scores.mean():.4f} (Â± {scores.std():.4f})\")\n",
    "\n",
    "# perform cross-validation\n",
    "cross_validate_classifiers(X, y, classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2111dc-423b-4b56-83b7-000beb4ed324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET 2: LUNG CANCER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cd42db-201d-498c-8cbe-990bd236384a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "df = pd.read_csv('lung-cancer.data', header=None, na_values=\"?\")\n",
    "\n",
    "# column names\n",
    "columns = ['target'] + [f'feature_{i}' for i in range(1, 57)]\n",
    "df.columns = columns\n",
    "\n",
    "# drop missing values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "# show the shapes of X and y\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c35dcde-fc8e-44a2-b454-73d28be348f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifiers and hyperparameter grids\n",
    "param_grids = {\n",
    "    \"SVM\": {\n",
    "        \"C\": [0.1, 1, 10, 100],\n",
    "        \"gamma\": [0.01, 0.1, 1, 'scale'],\n",
    "        \"kernel\": [\"rbf\", \"linear\"]\n",
    "    },\n",
    "    \"Random Forest\": {\n",
    "        \"n_estimators\": [50, 100, 200],\n",
    "        \"max_depth\": [None, 5, 10, 20],\n",
    "        \"min_samples_split\": [2, 5, 10]\n",
    "    },\n",
    "    \"KNN\": {\n",
    "        \"n_neighbors\": list(range(1, len(X))),\n",
    "        \"weights\": [\"uniform\", \"distance\"],\n",
    "        \"metric\": [\"euclidean\", \"manhattan\"]\n",
    "    },\n",
    "    \"Logistic Regression\": {\n",
    "        \"C\": [0.01, 0.1, 1, 10, 100],\n",
    "        \"penalty\": [\"l2\"],\n",
    "        \"solver\": [\"lbfgs\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "classifiers = {\n",
    "    \"SVM\": SVC(),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42)\n",
    "}\n",
    "\n",
    "# using leave one out cross validation because of small dataset size\n",
    "# using stratified kfold for svm because it performs better \n",
    "best_models = {}\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "for clf_name, clf in classifiers.items():\n",
    "    print(f\"\\n--- Tuning Hyper-Parameters for {clf_name} ---\")\n",
    "    \n",
    "    if clf_name == \"KNN\":\n",
    "        max_neighbors = len(X) - 1\n",
    "        param_grids[\"KNN\"][\"n_neighbors\"] = list(range(1, max_neighbors + 1))\n",
    "        grid_search = GridSearchCV(clf, param_grids[clf_name], cv=loo, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "    elif clf_name == \"SVM\":\n",
    "        grid_search = GridSearchCV(clf, param_grids[clf_name], cv=skf, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "    else:\n",
    "        grid_search = GridSearchCV(clf, param_grids[clf_name], cv=loo, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "\n",
    "    grid_search.fit(X_scaled, y)\n",
    "    best_models[clf_name] = grid_search.best_estimator_\n",
    "    print(f\"Best Parameters for {clf_name}: {grid_search.best_params_}\")\n",
    "    print(f\"Best Accuracy: {grid_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0126857a-c49e-4cb9-b168-2137bd98f524",
   "metadata": {},
   "outputs": [],
   "source": [
    "### evaluating classifiers with different training and test sizes\n",
    "def evaluate_with_partitions(X, y, models, n_repeats=3):\n",
    "    splits = {\n",
    "        \"20/80\": 0.2,\n",
    "        \"50/50\": 0.5,\n",
    "        \"80/20\": 0.8\n",
    "    }\n",
    "    \n",
    "    for split_name, test_size in splits.items():\n",
    "        print(f\"\\n--- Train-Test Split: {split_name} ---\")\n",
    "        \n",
    "        for _ in range(n_repeats):\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=None, stratify=y)\n",
    "            \n",
    "            for clf_name, clf in models.items():\n",
    "                # For KNN, set n_neighbors dynamically based on train set size\n",
    "                if clf_name == \"KNN\":\n",
    "                    n_neighbors = min(7, len(X_train))\n",
    "                    clf.set_params(n_neighbors=n_neighbors)\n",
    "                \n",
    "                # Train the classifier\n",
    "                clf.fit(X_train, y_train)\n",
    "                \n",
    "                # Predict and calculate accuracy\n",
    "                y_train_pred = clf.predict(X_train)\n",
    "                y_test_pred = clf.predict(X_test)\n",
    "                \n",
    "                train_acc = accuracy_score(y_train, y_train_pred)\n",
    "                test_acc = accuracy_score(y_test, y_test_pred)\n",
    "                \n",
    "                print(f\"{clf_name}: Train Accuracy = {train_acc:.4f}, Test Accuracy = {test_acc:.4f}\")\n",
    "\n",
    "evaluate_with_partitions(X_scaled, y, best_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451f5624-5dee-42ad-bf8d-b7b131b1b72f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_learning_curve(model, X, y, title):\n",
    "    train_sizes, train_scores, val_scores = learning_curve(\n",
    "        model, X, y, cv=loo, scoring='accuracy', train_sizes=np.linspace(0.1, 1.0, 10), n_jobs=-1\n",
    "    )\n",
    "\n",
    "    train_mean = np.mean(train_scores, axis=1)\n",
    "    train_std = np.std(train_scores, axis=1)\n",
    "    val_mean = np.mean(val_scores, axis=1)\n",
    "    val_std = np.std(val_scores, axis=1)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_sizes, train_mean, 'o-', color=\"r\", label=\"Training Accuracy\")\n",
    "    plt.plot(train_sizes, val_mean, 'o-', color=\"g\", label=\"Validation Accuracy\")\n",
    "    plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.1, color=\"r\")\n",
    "    plt.fill_between(train_sizes, val_mean - val_std, val_mean + val_std, alpha=0.1, color=\"g\")\n",
    "    \n",
    "    plt.title(f\"Learning Curve for {title}\")\n",
    "    plt.xlabel(\"Training Size\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "# plot learning curves for each classifier\n",
    "for clf_name, clf in best_models.items():\n",
    "    plot_learning_curve(clf, X_scaled, y, clf_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8ef400-93bb-4398-92c4-503d73d7b8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_classifiers(X, y, classifiers, cv=5):\n",
    "    print(\"\\n--- Cross-Validation Results for Lung Cancer Dataset ---\")\n",
    "    \n",
    "    for clf_name, clf in classifiers.items():\n",
    "        scores = cross_val_score(clf, X, y, cv=cv, scoring='accuracy')\n",
    "        print(f\"{clf_name}: Mean Accuracy = {scores.mean():.4f} (\\u00b1 {scores.std():.4f})\")\n",
    "\n",
    "# perform cross-validation\n",
    "cross_validate_classifiers(X_scaled, y, best_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509cd89d-31e0-4307-a1e4-69083570904c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET 3: BREAST CANCER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f89ba1d-fa25-4863-abc9-68cc7d5f1966",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [\n",
    "    'ID', 'Diagnosis',\n",
    "    'Radius_Mean', 'Texture_Mean', 'Perimeter_Mean', 'Area_Mean', 'Smoothness_Mean', \n",
    "    'Compactness_Mean', 'Concavity_Mean', 'Concave_Points_Mean', 'Symmetry_Mean', 'Fractal_Dimension_Mean',\n",
    "    'Radius_StdErr', 'Texture_StdErr', 'Perimeter_StdErr', 'Area_StdErr', 'Smoothness_StdErr',\n",
    "    'Compactness_StdErr', 'Concavity_StdErr', 'Concave_Points_StdErr', 'Symmetry_StdErr', 'Fractal_Dimension_StdErr',\n",
    "    'Radius_Worst', 'Texture_Worst', 'Perimeter_Worst', 'Area_Worst', 'Smoothness_Worst',\n",
    "    'Compactness_Worst', 'Concavity_Worst', 'Concave_Points_Worst', 'Symmetry_Worst', 'Fractal_Dimension_Worst'\n",
    "]\n",
    "\n",
    "\n",
    "df = pd.read_csv('wdbc.data', names=column_names)\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "df.drop('ID', axis=1, inplace=True)\n",
    "\n",
    "# convert 'Diagnosis' to binary (1 = Malignant, 0 = Benign)\n",
    "df['Diagnosis'] = df['Diagnosis'].apply(lambda x: 1 if x == 'M' else 0)\n",
    "\n",
    "X = df.drop('Diagnosis', axis=1)\n",
    "y = df['Diagnosis']\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a88df77-be8e-4c8f-8ada-a843080a794d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifiers and hyperparameter grids\n",
    "param_grids = {\n",
    "    \"SVM\": {\n",
    "        \"C\": [0.1, 1, 10, 100],\n",
    "        \"gamma\": [0.01, 0.1, 1, 'scale'],\n",
    "        \"kernel\": [\"rbf\", \"linear\"]\n",
    "    },\n",
    "    \"Random Forest\": {\n",
    "        \"n_estimators\": [50, 100, 200],\n",
    "        \"max_depth\": [None, 5, 10, 20],\n",
    "        \"min_samples_split\": [2, 5, 10]\n",
    "    },\n",
    "    \"KNN\": {\n",
    "        \"n_neighbors\": [3, 5, 7, 9, 11],\n",
    "        \"weights\": [\"uniform\", \"distance\"],\n",
    "        \"metric\": [\"euclidean\", \"manhattan\"]\n",
    "    },\n",
    "    \"Logistic Regression\": {\n",
    "        \"C\": [0.01, 0.1, 1, 10, 100],\n",
    "        \"penalty\": [\"l2\"],\n",
    "        \"solver\": [\"lbfgs\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "classifiers = {\n",
    "    \"SVM\": SVC(),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c98e7eb-579f-4967-a9a7-e3a1e38f18c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using stratified kfold for hyperparameter tuning \n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "best_models = {}\n",
    "\n",
    "for clf_name, clf in classifiers.items():\n",
    "    print(f\"\\n--- Tuning Hyper-Parameters for {clf_name} ---\")\n",
    "    grid_search = GridSearchCV(clf, param_grids[clf_name], cv=skf, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "    grid_search.fit(X_scaled, y)\n",
    "    best_models[clf_name] = grid_search.best_estimator_\n",
    "    print(f\"Best Parameters for {clf_name}: {grid_search.best_params_}\")\n",
    "    print(f\"Best 5-Fold CV Accuracy: {grid_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88da5375-9511-4bfe-b576-0dfe1eccfd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_with_partitions(X, y, models, n_repeats=3):\n",
    "    splits = {\n",
    "        \"20/80\": 0.2,\n",
    "        \"50/50\": 0.5,\n",
    "        \"80/20\": 0.8\n",
    "    }\n",
    "    \n",
    "    for split_name, test_size in splits.items():\n",
    "        print(f\"\\n--- Train-Test Split: {split_name} ---\")\n",
    "        \n",
    "        for _ in range(n_repeats):\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=None, stratify=y)\n",
    "            \n",
    "            for clf_name, clf in models.items():\n",
    "                clf.fit(X_train, y_train)\n",
    "                \n",
    "                # predict and calculate accuracy\n",
    "                y_train_pred = clf.predict(X_train)\n",
    "                y_test_pred = clf.predict(X_test)\n",
    "                \n",
    "                train_acc = accuracy_score(y_train, y_train_pred)\n",
    "                test_acc = accuracy_score(y_test, y_test_pred)\n",
    "                \n",
    "                print(f\"{clf_name}: Train Accuracy = {train_acc:.4f}, Test Accuracy = {test_acc:.4f}\")\n",
    "\n",
    "# evaluate classifiers with tuned hyper-parameters\n",
    "evaluate_with_partitions(X_scaled, y, best_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4a38bf-fb75-4813-8b1b-1acd5f11ae24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(model, X, y, title):\n",
    "    train_sizes, train_scores, val_scores = learning_curve(\n",
    "        model, X, y, cv=5, scoring='accuracy', train_sizes=np.linspace(0.1, 1.0, 10), n_jobs=-1\n",
    "    )\n",
    "\n",
    "    train_mean = np.mean(train_scores, axis=1)\n",
    "    train_std = np.std(train_scores, axis=1)\n",
    "    val_mean = np.mean(val_scores, axis=1)\n",
    "    val_std = np.std(val_scores, axis=1)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_sizes, train_mean, 'o-', color=\"r\", label=\"Training Accuracy\")\n",
    "    plt.plot(train_sizes, val_mean, 'o-', color=\"g\", label=\"Validation Accuracy\")\n",
    "    plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.1, color=\"r\")\n",
    "    plt.fill_between(train_sizes, val_mean - val_std, val_mean + val_std, alpha=0.1, color=\"g\")\n",
    "    \n",
    "    plt.title(f\"Learning Curve for {title}\")\n",
    "    plt.xlabel(\"Training Size\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "# plot learning curves for each classifier\n",
    "for clf_name, clf in best_models.items():\n",
    "    plot_learning_curve(clf, X_scaled, y, clf_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39698038-bbdf-4357-abbb-8789d956f5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_classifiers(X, y, classifiers, cv=5):\n",
    "    print(\"\\n--- Cross-Validation Results for Breast Cancer Dataset ---\")\n",
    "    \n",
    "    for clf_name, clf in classifiers.items():\n",
    "        scores = cross_val_score(clf, X, y, cv=cv, scoring='accuracy')\n",
    "        print(f\"{clf_name}: Mean Accuracy = {scores.mean():.4f} (\\u00b1 {scores.std():.4f})\")\n",
    "\n",
    "# perform cross-validation\n",
    "cross_validate_classifiers(X_scaled, y, best_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8382bd7-e5b7-46af-b75a-341dc5934b12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
